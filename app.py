import streamlit as st
import pandas as pd
import requests
import re

# --- –ù–ê–°–¢–†–û–ô–ö–ê ---
TMDB_API_KEY = st.secrets.get("TMDB_API_KEY", "YOUR_TMDB_API_KEY_HERE") 
tmdb_api_base_url = "https://api.themoviedb.org/3"

# ID –∫–æ–º–ø–∞–Ω–∏–π Disney –∏ –µ–µ –¥–æ—á–µ—Ä–Ω–∏—Ö —Å—Ç—É–¥–∏–π –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
DISNEY_COMPANY_IDS = {
    2,       # Walt Disney Pictures
    3,       # Pixar
    6125,    # Walt Disney Animation Studios
    420,     # Marvel Studios
    1,       # Lucasfilm Ltd.
    10282,   # Searchlight Pictures (—Ä–∞–Ω–µ–µ Fox Searchlight)
    127928   # 20th Century Studios (—Ä–∞–Ω–µ–µ 20th Century Fox)
}

# --- –§–£–ù–ö–¶–ò–ò-–ü–û–ú–û–©–ù–ò–ö–ò ---

@st.cache_data
def load_data():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –∫—ç—à–∏—Ä—É–µ—Ç CSV —Ñ–∞–π–ª—ã."""
    try:
        data = {
            "works": pd.read_csv("–ü—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è.csv"),
            "performers": pd.read_csv("–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–∏.csv"),
        }
        data["works"]["Name"] = data["works"]["Name"].astype(str)
        data["performers"]["Name"] = data["performers"]["Name"].astype(str)
        return data
    except FileNotFoundError as e:
        st.error(f"–û—à–∏–±–∫–∞: –ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª {e.filename}.")
        return None

def find_entity_by_name(query, dataframe):
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –≤ DataFrame."""
    if dataframe is None or not query:
        return None
    result = dataframe[dataframe["Name"].str.contains(query, case=False, na=False)]
    return result if not result.empty else None

def clean_notion_links(text):
    """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç —Å—Å—ã–ª–æ–∫ Notion –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫."""
    if not isinstance(text, str): return ["-"]
    cleaned_text = re.sub(r"\(https://www.notion.so/[^)]+\)", "", text)
    items = [item.strip().strip('"') for item in cleaned_text.split(',')]
    return items

def display_field(label, value, extra=""):
    """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç —Å—Ç—Ä–æ–∫—É '–ú–µ—Ç–∫–∞: –ó–Ω–∞—á–µ–Ω–∏–µ', —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."""
    if pd.notna(value) and str(value).strip() not in ['', '-']:
        st.write(f"**{label}:** {value}{extra}")

def display_list(items_list, title):
    """–ö—Ä–∞—Å–∏–≤–æ –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –ø–æ–¥ —Ä–∞—Å–∫—Ä—ã–≤–∞—é—â–∏–º—Å—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–º."""
    with st.expander(title):
        if items_list and items_list != ['-']:
            for item in items_list: st.markdown(f"- {item.strip()}")
        else:
            st.write("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö.")

# --- –§–£–ù–ö–¶–ò–ò –ü–û–ò–°–ö–ê –í TMDB ---

def get_movie_details(query, year=None):
    """–ò—â–µ—Ç —Ñ–∏–ª—å–º—ã TMDb, –§–ò–õ–¨–¢–†–£–ï–¢ –ø–æ –∫–æ–º–ø–∞–Ω–∏—è–º Disney –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –°–ü–ò–°–û–ö."""
    if not TMDB_API_KEY or TMDB_API_KEY == "YOUR_TMDB_API_KEY_HERE": return []
    
    search_query = query.split(':')[0].strip() if ':' in query else query
    search_url = f"{tmdb_api_base_url}/search/movie"
    params = {"api_key": TMDB_API_KEY, "query": search_query, "language": "ru-RU", "page": 1}
    if year:
        params['primary_release_year'] = year
    
    try:
        response = requests.get(search_url, params=params)
        response.raise_for_status()
        data = response.json()
        
        disney_movies = []
        for movie_summary in data.get("results", []):
            movie_id = movie_summary.get("id")
            if not movie_id: continue

            details_url = f"{tmdb_api_base_url}/movie/{movie_id}"
            details_params = {"api_key": TMDB_API_KEY, "language": "ru-RU"}
            details_response = requests.get(details_url, params=details_params)
            movie_details = details_response.json()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–º–ø–∞–Ω–∏–∏
            producer_ids = {company['id'] for company in movie_details.get("production_companies", [])}
            if producer_ids.intersection(DISNEY_COMPANY_IDS):
                poster_path = movie_details.get("poster_path")
                disney_movies.append({
                    "title": movie_details.get("title"),
                    "overview": movie_details.get("overview", "–°—é–∂–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω."),
                    "image_url": f"https://image.tmdb.org/t/p/w500{poster_path}" if poster_path else None,
                    "release_date": movie_details.get("release_date"),
                    "vote_average": movie_details.get("vote_average")
                })
            if len(disney_movies) >= 10: # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 10 Disney-—Ñ–∏–ª—å–º–æ–≤
                break
        return disney_movies
    except requests.exceptions.RequestException:
        return []

def get_person_details(query):
    """–ò—â–µ—Ç –ª—é–¥–µ–π –≤ TMDb –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –°–ü–ò–°–û–ö –¥–æ 10 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."""
    if not TMDB_API_KEY or TMDB_API_KEY == "YOUR_TMDB_API_KEY_HERE": return []
    # ... (–∫–æ–¥ –¥–ª—è —ç—Ç–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
    search_url = f"{tmdb_api_base_url}/search/person"
    params = {"api_key": TMDB_API_KEY, "query": query, "language": "ru-RU"}
    
    try:
        response = requests.get(search_url, params=params)
        response.raise_for_status()
        data = response.json()
        
        results = []
        for person_summary in data.get("results", [])[:10]:
            person_id = person_summary.get("id")
            if not person_id: continue

            details_url = f"{tmdb_api_base_url}/person/{person_id}"
            details_params = {"api_key": TMDB_API_KEY, "language": "ru-RU"}
            details_response = requests.get(details_url, params=details_params)
            details_response.raise_for_status()
            details = details_response.json()
            
            profile_path = details.get("profile_path")
            results.append({
                "name": details.get("name"),
                "biography": details.get("biography", "–ë–∏–æ–≥—Ä–∞—Ñ–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞."),
                "image_url": f"https://image.tmdb.org/t/p/w500{profile_path}" if profile_path else None,
                "birthday": details.get("birthday"),
                "place_of_birth": details.get("place_of_birth"),
                "known_for": details.get("known_for_department")
            })
        return results
    except requests.exceptions.RequestException:
        return []

# --- –ì–õ–ê–í–ù–ê–Ø –ß–ê–°–¢–¨ –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø ---

st.set_page_config(page_title="–£–º–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –º–∏—Ä—É Disney", layout="wide")
st.title("‚ú® –£–º–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –º–∏—Ä—É Disney")

dataframes = load_data()

if dataframes:
    st.sidebar.title("–ù–∞–≤–∏–≥–∞—Ü–∏—è")
    search_type = st.sidebar.radio("–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–¥–µ–ª:", ("–ü—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ", "–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å"))

    if search_type == "–ü—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ":
        st.header("üé¨ –ü–æ–∏—Å–∫ –ø–æ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è–º")
        query = st.text_input("–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è:", "–ö—Ä–∞—Å–∞–≤–∏—Ü–∞ –∏ —á—É–¥–æ–≤–∏—â–µ")
        if st.button("üîç –ù–∞–π—Ç–∏", key="work_search"):
            
            displayed_items = set() 
            local_results = find_entity_by_name(query, dataframes["works"])
            
            if local_results is not None:
                st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ –≤–∞—à–µ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
                for _, row in local_results.iterrows():
                    year = int(row['–ì–æ–¥ –≤—ã–ø—É—Å–∫–∞']) if pd.notna(row['–ì–æ–¥ –≤—ã–ø—É—Å–∫–∞']) else 0
                    title_cleaned = row['Name'].split(':')[0].strip().lower()
                    displayed_items.add((title_cleaned, year))
                    
                    details_list = get_movie_details(row["Name"], year=year)
                    details = details_list[0] if details_list else None
                    
                    st.markdown(f"<div style='background-color:#28a745; padding: 10px; border-radius: 5px; color: white; margin-bottom: 10px;'><b>{row['Name']}</b></div>", unsafe_allow_html=True)
                    col1, col2 = st.columns([1, 2.5])
                    with col1:
                        if details and details['image_url']:
                            st.image(details['image_url'])
                    with col2:
                        display_field("–ì–æ–¥ –≤—ã–ø—É—Å–∫–∞", year if year != 0 else "–ù–µ —É–∫–∞–∑–∞–Ω")
                        display_field("–¢–∏–ø", row.get('–¢–∏–ø'))
                        display_field("–ñ–∞–Ω—Ä", row.get('–ñ–∞–Ω—Ä'))
                        display_field("–†–µ–π—Ç–∏–Ω–≥", row.get('–†–µ–π—Ç–∏–Ω–≥'))
                        display_field("–í–æ–∑—Ä–∞—Å—Ç", row.get('–í–æ–∑—Ä–∞—Å—Ç'))
                        display_field("–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å", row.get('–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å'))
                        display_field("–°—Ç—É–¥–∏—è", clean_notion_links(row.get('–°—Ç—É–¥–∏—è'))[0] if pd.notna(row.get('–°—Ç—É–¥–∏—è')) else None)
                        display_field("–ë—é–¥–∂–µ—Ç –∏ —Å–±–æ—Ä—ã", row.get('–ë—é–¥–∂–µ—Ç –∏ —Å–±–æ—Ä—ã'))
                        display_field("–ù–∞–≥—Ä–∞–¥—ã", row.get('–ù–∞–≥—Ä–∞–¥—ã'))

                    if details and details['overview']:
                        with st.expander("–°—é–∂–µ—Ç"): st.write(details['overview'])
                    display_list(clean_notion_links(row.get('–ü–µ—Ä—Å–æ–Ω–∞–∂–∏')), "–ü–µ—Ä—Å–æ–Ω–∞–∂–∏")
                    display_list(clean_notion_links(row.get('–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–∏')), "–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–∏")
                    display_list(clean_notion_links(row.get('–ü–µ—Å–Ω–∏')), "–ü–µ—Å–Ω–∏")
                    st.divider()
            else:
                st.warning("–í –≤–∞—à–µ–π –±–∞–∑–µ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")

            st.subheader("üåê –ù–∞–π–¥–µ–Ω–æ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ (TMDb)")
            internet_results = get_movie_details(query)
            
            new_results_found = False
            if internet_results:
                for internet_result in internet_results:
                    release_date = internet_result.get('release_date')
                    internet_year = int(release_date.split('-')[0]) if release_date and '-' in release_date else 0
                    
                    check_tuple = (internet_result['title'].split(':')[0].strip().lower(), internet_year)
                    if check_tuple in displayed_items:
                        continue 
                    
                    new_results_found = True
                    st.markdown(f"<div style='background-color:#17a2b8; padding: 10px; border-radius: 5px; color: white; margin-bottom: 10px;'><b>{internet_result['title']}</b></div>", unsafe_allow_html=True)
                    col1, col2 = st.columns([1, 2.5])
                    with col1:
                        if internet_result['image_url']: st.image(internet_result['image_url'])
                    with col2:
                        display_field("–î–∞—Ç–∞ —Ä–µ–ª–∏–∑–∞", internet_result.get('release_date'))
                        display_field("–†–µ–π—Ç–∏–Ω–≥ –∑—Ä–∏—Ç–µ–ª–µ–π", f"{internet_result.get('vote_average'):.1f} / 10" if internet_result.get('vote_average') else None)
                        with st.expander("–°—é–∂–µ—Ç"):
                            st.write(internet_result.get('overview'))
                    st.divider()
            
            if not new_results_found:
                st.info("–í—Å–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞ —É–∂–µ –ø–æ–∫–∞–∑–∞–Ω—ã –≤ –≤–∞—à–µ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")

    elif search_type == "–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å":
        st.header("üë§ –ü–æ–∏—Å–∫ –ø–æ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è–º")
        query = st.text_input("–í–≤–µ–¥–∏—Ç–µ –∏–º—è –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è:", "–î–∂–æ–Ω–Ω–∏ –î–µ–ø–ø")
        if st.button("üîç –ù–∞–π—Ç–∏", key="performer_search"):
            local_results = find_entity_by_name(query, dataframes["performers"])

            if local_results is not None:
                st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ –≤–∞—à–µ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
                for _, row in local_results.iterrows():
                    details_list = get_person_details(row["Name"])
                    details = details_list[0] if details_list else None
                    
                    st.markdown(f"<div style='background-color:#28a745; padding: 10px; border-radius: 5px; color: white; margin-bottom: 10px;'><b>{row['Name']}</b></div>", unsafe_allow_html=True)
                    col1, col2 = st.columns([1, 2.5])
                    with col1:
                        if details and details['image_url']: st.image(details['image_url'])
                    with col2:
                        display_field("–ö–∞—Ä—å–µ—Ä–∞", row.get('–ö–∞—Ä—å–µ—Ä–∞'))
                        display_field("–î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è", row.get('–î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è'))
                        display_field("–ó–Ω–∞–∫ –∑–æ–¥–∏–∞–∫–∞", row.get('–ó–Ω–∞–∫ –∑–æ–¥–∏–∞–∫–∞'))
                        display_field("–ú–µ—Å—Ç–æ —Ä–æ–∂–¥–µ–Ω–∏—è", row.get('–ú–µ—Å—Ç–æ —Ä–æ–∂–¥–µ–Ω–∏—è'))
                        display_field("–î–∞—Ç–∞ —Å–º–µ—Ä—Ç–∏", row.get('–î–∞—Ç–∞ —Å–º–µ—Ä—Ç–∏'))
                        display_field("–ú–µ—Å—Ç–æ —Å–º–µ—Ä—Ç–∏", row.get('–ú–µ—Å—Ç–æ —Å–º–µ—Ä—Ç–∏'))
                        display_field("–†–æ—Å—Ç", row.get('–†–æ—Å—Ç'), extra=" –º")
                        display_field("–í—Å–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–æ–≤", row.get('–í—Å–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–æ–≤'))
                    
                    if details and details['biography']:
                        with st.expander("–ë–∏–æ–≥—Ä–∞—Ñ–∏—è"): st.write(details['biography'])
                    display_list(clean_notion_links(row.get('–§–∏–ª—å–º–æ–≥—Ä–∞—Ñ–∏—è')), "–§–∏–ª—å–º–æ–≥—Ä–∞—Ñ–∏—è")
                    display_list(clean_notion_links(row.get('–°—ã–≥—Ä–∞–Ω–Ω—ã–µ/–æ–∑–≤—É—á–µ–Ω–Ω—ã–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–∏')), "–ü–µ—Ä—Å–æ–Ω–∞–∂–∏")
                    st.divider()
            else:
                st.warning("–í –≤–∞—à–µ–π –±–∞–∑–µ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ...")
                internet_results = get_person_details(query)
                if internet_results:
                    st.subheader("üåê –ù–∞–π–¥–µ–Ω–æ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ (TMDb)")
                    for internet_result in internet_results:
                        st.markdown(f"<div style='background-color:#17a2b8; padding: 10px; border-radius: 5px; color: white; margin-bottom: 10px;'><b>{internet_result['name']}</b></div>", unsafe_allow_html=True)
                        col1, col2 = st.columns([1, 2.5])
                        with col1:
                            if internet_result['image_url']: st.image(internet_result['image_url'])
                        with col2:
                            display_field("–û—Å–Ω–æ–≤–Ω–∞—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å", internet_result.get('known_for'))
                            display_field("–î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è", internet_result.get('birthday'))
                            display_field("–ú–µ—Å—Ç–æ —Ä–æ–∂–¥–µ–Ω–∏—è", internet_result.get('place_of_birth'))
                        
                        if internet_result['biography']:
                            with st.expander("–ë–∏–æ–≥—Ä–∞—Ñ–∏—è"): st.write(internet_result['biography'])
                        st.divider()
                else:
                    st.error("–í –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ —Ç–∞–∫–∂–µ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
